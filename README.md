Papers: Data Generation For ReID
===

Included Conferences: CVPR, ICCV, ECCV, NeurIPS, WACV, etc.

 -   [View Synthesis](#View-Synthesis)  
 -   [Style Synthesis](#Style-Synthesis)  
 -   [Multi-View Stereo (MVS)](#MVS)    
<!--     -   [CVPR 2022](#CVPR-2022) -->

## View Synthesis

#### CVPR 2022  

+ Multi-View Consistent Generative Adversarial Networks for 3D-Aware Image Synthesis    
[[paper](http://arxiv.org/abs/2204.06307)]  [[code]()]
  <details>
    <summary>Notes</summary>
  </details>

+ (Scene) FWD: Real-Time Novel View Synthesis With Forward Warping and Depth     
[[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_FWD_Real-Time_Novel_View_Synthesis_With_Forward_Warping_and_Depth_CVPR_2022_paper.pdf)]  [[code]()]
 
+ (Block, Buildings) Block-NeRF: Scalable Large Scene Neural View Synthesis       
[[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Tancik_Block-NeRF_Scalable_Large_Scene_Neural_View_Synthesis_CVPR_2022_paper.pdf)]  [[code]()]

+ (Scene) Scene Representation Transformer: Geometry-Free Novel View Synthesis Through Set-Latent Scene Representations  
[[paper](http://arxiv.org/abs/2111.13152)]  [[code]()]
 
+ (Scene) NeurMiPs: Neural Mixture of Planar Experts for View Synthesis      
[[paper](http://arxiv.org/abs/2204.13696)]  [[code]()]
 
+ (Scene) Boosting View Synthesis With Residual Transfer  
[[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Rong_Boosting_View_Synthesis_With_Residual_Transfer_CVPR_2022_paper.pdf)]  [[code]()]

+ (Sprase input) RegNeRF: Regularizing Neural Radiance Fields for View Synthesis From Sparse Inputs       
[[paper](http://arxiv.org/abs/2112.00724)]  [[code]()]

+ AutoRF: Learning 3D Object Radiance Fields From Single View Observations       
[[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Muller_AutoRF_Learning_3D_Object_Radiance_Fields_From_Single_View_Observations_CVPR_2022_paper.pdf)]  [[code]()]
  <details>
    <summary>Notes</summary>
  </details>
 
+ (Spherical input) SOMSI: Spherical Novel View Synthesis With Soft Occlusion Multi-Sphere Images       
[[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Habtegebrial_SOMSI_Spherical_Novel_View_Synthesis_With_Soft_Occlusion_Multi-Sphere_Images_CVPR_2022_paper.pdf)]  [[code]()]
 
+ (Human, Face render) JIFF: Jointly-Aligned Implicit Face Function for High Quality Single View Clothed Human Reconstruction   
[[paper](http://arxiv.org/abs/2204.10549)]  [[code]()]
 
+ (HDR NERF) NeRF in the Dark: High Dynamic Range View Synthesis From Noisy Raw Images       
[[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Mildenhall_NeRF_in_the_Dark_High_Dynamic_Range_View_Synthesis_From_CVPR_2022_paper.pdf)]  [[code]()]
 

#### ICCV 2021   

+ (Human) Attack-Guided Perceptual Data Generation for Real-World Re-Identification  
[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_Attack-Guided_Perceptual_Data_Generation_for_Real-World_Re-Identification_ICCV_2021_paper.pdf)]  [[code]()]
 
 
+ (Vedio) Neural Radiance Flow for 4D View Synthesis and Video Processing     
[[paper](http://arxiv.org/abs/2012.09790)]  [[code]()]
 
+ (Scene) Geometry-Free View Synthesis: Transformers and No 3D Priors        
[[paper](http://arxiv.org/abs/2104.07652)]  [[code]()]
 
+ (Monocular: Vedio moving views) Dynamic View Synthesis From Dynamic Monocular Video       
[[paper](http://arxiv.org/abs/2105.06468)]  [[code]()]
 
+ Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis       
[[paper](http://arxiv.org/abs/2104.00677)]  [[code]()]
 
+ Baking Neural Radiance Fields for Real-Time View Synthesis       
[[paper](http://arxiv.org/abs/2103.14645)]  [[code]()]
 
+ (Vedio) Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Dynamic Scene From Monocular Video     
[[paper](http://arxiv.org/abs/2012.12247)]  [[code]()]
 
+ (Scene, MPI) MINE: Towards Continuous Depth MPI With NeRF for Novel View Synthesis      
[[paper](http://arxiv.org/abs/2103.14910)]  [[code]()]
 
+ Worldsheet: Wrapping the World in a 3D Sheet for View Synthesis From a Single Image       
[[paper](http://arxiv.org/abs/2012.09854)]  [[code]()]
 
+ (Vedio) Deep 3D Mask Volume for View Synthesis of Dynamic Scenes     
[[paper](http://arxiv.org/abs/2108.13408)]  [[code]()]
 
#### CVPR 2021  

+ Joint Generative and Contrastive Learning for Unsupervised Person Re-Identification  
[[paper](http://arxiv.org/abs/2012.09071)]  [[code]()]

+ Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes   
[[paper](http://arxiv.org/abs/2104.06935)]  [[code]()]
 
+ Stable View Synthesis     
[[paper](http://arxiv.org/abs/2011.07233)]  [[code]()]
 
+ (Scene, Panorama input) Layout-Guided Novel View Synthesis From a Single Indoor Panorama      
[[paper](http://arxiv.org/abs/2103.17022)]  [[code]()]
 
+ Learning Neural Representation of Camera Pose with Matrix Representation of Pose Shift via View Synthesis       
[[paper](http://arxiv.org/abs/2104.01508)]  [[code]()]
  
+ ID-Unet: Iterative Soft and Hard Deformation for View Synthesis       
[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_ID-Unet_Iterative_Soft_and_Hard_Deformation_for_View_Synthesis_CVPR_2021_paper.pdf)]  [[code]()]
  <details>
    <summary>Notes</summary>
  </details>
  
+ (Scene) NeX: Real-Time View Synthesis With Neural Basis Expansion     
[[paper](http://arxiv.org/abs/2103.05606)]  [[code]()]
  
+ (Human body) Neural Body: Implicit Neural Representations With Structured Latent Codes for Novel View Synthesis of Dynamic Humans       
[[paper](http://arxiv.org/abs/2012.15838)]  [[code]()]
  
+ (Vedio) Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes     
[[paper](http://arxiv.org/abs/2011.13084)]  [[code]()]
  
+ (Novel lighting) NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis     
[[paper](http://arxiv.org/abs/2012.03927)]  [[code]()]
  
+ (Scene) Self-Supervised Visibility Learning for Novel View Synthesis       
[[paper](http://arxiv.org/abs/2103.15407)]  [[code]()]
  
#### CVPR 2020   
 
+ (Scene) SynSin: End-to-End View Synthesis From a Single Image       
[[paper](http://arxiv.org/abs/1912.08804)]  [[code](http://arxiv.org/abs/1912.08804)]
  
+ (Monocular) Novel View Synthesis of Dynamic Scenes With Globally Coherent Depths From a Monocular Camera   
[[paper](http://arxiv.org/abs/2004.01294)]  [[code]()]
  
+ (Scene, MPI) Single-View View Synthesis With Multiplane Images       
[[paper](http://arxiv.org/abs/2004.11364)]  [[code]()]

#### ICCV 2019   
 
+ (Human: Pose, View, Appearance) Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis     
[[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Liquid_Warping_GAN_A_Unified_Framework_for_Human_Motion_Imitation_ICCV_2019_paper.pdf)]  [[code]()]
  
+ (Scene) Extreme View Synthesis       
[[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Choi_Extreme_View_Synthesis_ICCV_2019_paper.pdf)]  [[code]()]
  
+ View Independent Generative Adversarial Network for Novel View Synthesis     
[[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_View_Independent_Generative_Adversarial_Network_for_Novel_View_Synthesis_ICCV_2019_paper.pdf)]  [[code]()]
  <details>
    <summary>Note</summary>
    <img src="img/VI-GAN.png" alt="referformer" align=center />    
    - Key points:   
         - Four parts of LOSS: (1)View-independent(equal id of input view and generating view after encoding); (2)Recontruction(Minimize the distance between generating view and ground truth(directly and using VGG16), input view and reconstructing input view by DECODER, input view and re-generating input view through generating view.); (3)GAN loss(improve realism); (4)Pose prediction loss(second discriminator predicts target views(P_B) when inputting GT and generating images).    
         - Use an ENCODER for the disentangling task(extracting view-independent intrinsic features) and a DECODER for the rendering task(generating target view).    
  
  </details>

+ Pixel2Mesh++: Multi-View 3D Mesh Generation via Deformation       
[[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Wen_Pixel2Mesh_Multi-View_3D_Mesh_Generation_via_Deformation_ICCV_2019_paper.pdf)]  [[code]()]

#### CVPR 2019

+ (Scene) DeepView: View Synthesis With Learned Gradient Descent       
[[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Flynn_DeepView_View_Synthesis_With_Learned_Gradient_Descent_CVPR_2019_paper.pdf)]  [[code]()]

+ (Scene) Structure-Preserving Stereoscopic View Synthesis With Multi-Scale Adversarial Correlation Matching       
[[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Structure-Preserving_Stereoscopic_View_Synthesis_With_Multi-Scale_Adversarial_Correlation_Matching_CVPR_2019_paper.pdf)]  [[code]()]








## Style Synthesis

#### CVPR 2022 

+ StylizedNeRF: Consistent 3D Scene Stylization As Stylized NeRF via 2D-3D Mutual Learning       
[[paper](http://arxiv.org/abs/2205.12183)]  [[code]()]

+ 3D Photo Stylization: Learning To Generate Stylized Novel Views From a Single Image       
[[paper](http://arxiv.org/abs/2112.00169)]  [[code]()]

#### CVPR 2020 
+ Stylization-Based Architecture for Fast Deep Exemplar Colorization       
[[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Stylization-Based_Architecture_for_Fast_Deep_Exemplar_Colorization_CVPR_2020_paper.pdf)]  [[code]()]

#### WACV 2020
+ (Human) Semantic Consistency and Identity Mapping Multi-Component Generative Adversarial Network for Person Re-Identification  
[[paper](https://openaccess.thecvf.com/content_WACV_2020/papers/Khatun_Semantic_Consistency_and_Identity_Mapping_Multi-Component_Generative_Adversarial_Network_for_WACV_2020_paper.pdf)]  [[code]()]

#### CVPR 2019 
+ (Human appearance) Joint Discriminative and Generative Learning for Person Re-Identification  
[[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Joint_Discriminative_and_Generative_Learning_for_Person_Re-Identification_CVPR_2019_paper.pdf)]  [[code]()]







## MVS

#### CVPR 2022  

+ Multi-View Mesh Reconstruction With Neural Deferred Shading   
[[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Worchel_Multi-View_Mesh_Reconstruction_With_Neural_Deferred_Shading_CVPR_2022_paper.pdf)]  [[code]()]
 
+ Topologically-Aware Deformation Fields for Single-View 3D Reconstruction  
[[paper](http://arxiv.org/abs/2205.06267)]  [[code]()]
 
+ FvOR: Robust Joint Shape and Pose Optimization for Few-View Object Reconstruction        
[[paper](http://arxiv.org/abs/2205.07763)]  [[code]()]
 
+ Efficient Multi-View Stereo by Iterative Dynamic Cost Volume       
[[paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Efficient_Multi-View_Stereo_by_Iterative_Dynamic_Cost_Volume_CVPR_2022_paper.pdf)]  [[code]()]
 
+ MVS2D: Efficient Multi-View Stereo via Attention-Driven 2D Convolutions   
[[paper](http://arxiv.org/abs/2104.13325)]  [[code]()]
 
#### ICCV 2021  

+ AA-RMVSNet: Adaptive Aggregation Recurrent Multi-View Stereo Network       
[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wei_AA-RMVSNet_Adaptive_Aggregation_Recurrent_Multi-View_Stereo_Network_ICCV_2021_paper.pdf)]  [[code]()]
 
+ A Confidence-Based Iterative Solver of Depths and Surface Normals for Deep Multi-View Stereo   
[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_A_Confidence-Based_Iterative_Solver_of_Depths_and_Surface_Normals_for_ICCV_2021_paper.pdf)]  [[code]()]
 
+ Multi-View 3D Reconstruction With Transformers      
[[paper](http://arxiv.org/abs/2103.12957)]  [[code]()]

+ NerfingMVS: Guided Optimization of Neural Radiance Fields for Indoor Multi-View Stereo       
[[paper](http://arxiv.org/abs/2109.01129)]  [[code]()]
 
+ MVSNeRF: Fast Generalizable Radiance Field Reconstruction From Multi-View Stereo     
[[paper](http://arxiv.org/abs/2103.15595)]  [[code]()]
 
+ Toward Realistic Single-View 3D Object Reconstruction With Unsupervised Learning From Multiple Images     
[[paper](http://arxiv.org/abs/2109.02288)]  [[code]()]
 
+ UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction   
[[paper](http://arxiv.org/abs/2104.10078)]  [[code]()]
 
+ Topologically Consistent Multi-View Face Inference Using Volumetric Sampling     
[[paper](http://arxiv.org/abs/2110.02948)]  [[code]()]


#### CVPR 2019 
+ (Human) Re-Identification Supervised Texture Generation  
[[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Re-Identification_Supervised_Texture_Generation_CVPR_2019_paper.pdf)]  [[code]()]
 


<!-- Comment -->

#### test

+ Paper     
[[paper]()]  [[code]()]
  <details>
    <summary>Notes</summary>
     <img src="img/VAMI.png" alt="referformer" align=center />  

    - Key points:
         - point1.
         - point2.
    </details>
